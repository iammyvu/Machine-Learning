{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll work with a dataset on sold houses in Ames, Iowa. Each row in the dataset describes the properties of a single house as well as the amount it was sold for. In this course, we'll build models that predict the final sale price from its other attributes. Specifically, we'll explore the following questions:\n",
    "\n",
    "* Which properties of a house most affect the final sale price?\n",
    "* How effectively can we predict the sale price from just its properties?\n",
    "\n",
    "Here are some of the columns:\n",
    "\n",
    " * Lot Area: Lot size in square feet.\n",
    " * Overall Qual: Rates the overall material and finish of the house.\n",
    " * Overall Cond: Rates the overall condition of the house.\n",
    " * Year Built: Original construction date.\n",
    " * Low Qual Fin SF: Low quality finished square feet (all floors).\n",
    " * Full Bath: Full bathrooms above grade.\n",
    " * Fireplaces: Number of fireplaces.\n",
    " * Let's start by generating train and test datasets and getting more familiar with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('AmesHousing.txt', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 82 columns):\n",
      "Order              1460 non-null int64\n",
      "PID                1460 non-null int64\n",
      "MS SubClass        1460 non-null int64\n",
      "MS Zoning          1460 non-null object\n",
      "Lot Frontage       1211 non-null float64\n",
      "Lot Area           1460 non-null int64\n",
      "Street             1460 non-null object\n",
      "Alley              109 non-null object\n",
      "Lot Shape          1460 non-null object\n",
      "Land Contour       1460 non-null object\n",
      "Utilities          1460 non-null object\n",
      "Lot Config         1460 non-null object\n",
      "Land Slope         1460 non-null object\n",
      "Neighborhood       1460 non-null object\n",
      "Condition 1        1460 non-null object\n",
      "Condition 2        1460 non-null object\n",
      "Bldg Type          1460 non-null object\n",
      "House Style        1460 non-null object\n",
      "Overall Qual       1460 non-null int64\n",
      "Overall Cond       1460 non-null int64\n",
      "Year Built         1460 non-null int64\n",
      "Year Remod/Add     1460 non-null int64\n",
      "Roof Style         1460 non-null object\n",
      "Roof Matl          1460 non-null object\n",
      "Exterior 1st       1460 non-null object\n",
      "Exterior 2nd       1460 non-null object\n",
      "Mas Vnr Type       1449 non-null object\n",
      "Mas Vnr Area       1449 non-null float64\n",
      "Exter Qual         1460 non-null object\n",
      "Exter Cond         1460 non-null object\n",
      "Foundation         1460 non-null object\n",
      "Bsmt Qual          1420 non-null object\n",
      "Bsmt Cond          1420 non-null object\n",
      "Bsmt Exposure      1419 non-null object\n",
      "BsmtFin Type 1     1420 non-null object\n",
      "BsmtFin SF 1       1459 non-null float64\n",
      "BsmtFin Type 2     1419 non-null object\n",
      "BsmtFin SF 2       1459 non-null float64\n",
      "Bsmt Unf SF        1459 non-null float64\n",
      "Total Bsmt SF      1459 non-null float64\n",
      "Heating            1460 non-null object\n",
      "Heating QC         1460 non-null object\n",
      "Central Air        1460 non-null object\n",
      "Electrical         1460 non-null object\n",
      "1st Flr SF         1460 non-null int64\n",
      "2nd Flr SF         1460 non-null int64\n",
      "Low Qual Fin SF    1460 non-null int64\n",
      "Gr Liv Area        1460 non-null int64\n",
      "Bsmt Full Bath     1459 non-null float64\n",
      "Bsmt Half Bath     1459 non-null float64\n",
      "Full Bath          1460 non-null int64\n",
      "Half Bath          1460 non-null int64\n",
      "Bedroom AbvGr      1460 non-null int64\n",
      "Kitchen AbvGr      1460 non-null int64\n",
      "Kitchen Qual       1460 non-null object\n",
      "TotRms AbvGrd      1460 non-null int64\n",
      "Functional         1460 non-null object\n",
      "Fireplaces         1460 non-null int64\n",
      "Fireplace Qu       743 non-null object\n",
      "Garage Type        1386 non-null object\n",
      "Garage Yr Blt      1385 non-null float64\n",
      "Garage Finish      1385 non-null object\n",
      "Garage Cars        1460 non-null float64\n",
      "Garage Area        1460 non-null float64\n",
      "Garage Qual        1385 non-null object\n",
      "Garage Cond        1385 non-null object\n",
      "Paved Drive        1460 non-null object\n",
      "Wood Deck SF       1460 non-null int64\n",
      "Open Porch SF      1460 non-null int64\n",
      "Enclosed Porch     1460 non-null int64\n",
      "3Ssn Porch         1460 non-null int64\n",
      "Screen Porch       1460 non-null int64\n",
      "Pool Area          1460 non-null int64\n",
      "Pool QC            1 non-null object\n",
      "Fence              297 non-null object\n",
      "Misc Feature       60 non-null object\n",
      "Misc Val           1460 non-null int64\n",
      "Mo Sold            1460 non-null int64\n",
      "Yr Sold            1460 non-null int64\n",
      "Sale Type          1460 non-null object\n",
      "Sale Condition     1460 non-null object\n",
      "SalePrice          1460 non-null int64\n",
      "dtypes: float64(11), int64(28), object(43)\n",
      "memory usage: 935.4+ KB\n"
     ]
    }
   ],
   "source": [
    "train = df[:1460]\n",
    "test = df[1460:]\n",
    "\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'SalePrice'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 700x1500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# For prettier plots.\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "plt.figure(figsize=(7,15))\n",
    "\n",
    "plt.subplot(311)\n",
    "plt.scatter(x=\"Garage Area\", y=\"SalePrice\", data=train)\n",
    "plt.subplot(312)\n",
    "plt.scatter(x=\"Gr Liv Area\", y=\"SalePrice\", data=train)\n",
    "plt.subplot(313)\n",
    "plt.scatter(x=\"Overall Cond\", y=\"SalePrice\", data=train)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the last screen, we can tell that the `Gr Liv Area` feature correlates the most with the `SalePrice` column. We can confirm this by calculating the correlation between pairs of these columns using the `pandas.DataFrame.corr()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Garage Area  Gr Liv Area  Overall Cond  SalePrice\n",
      "Garage Area      1.000000     0.465366     -0.132401   0.662397\n",
      "Gr Liv Area      0.465366     1.000000     -0.133710   0.698990\n",
      "Overall Cond    -0.132401    -0.133710      1.000000  -0.099395\n",
      "SalePrice        0.662397     0.698990     -0.099395   1.000000\n"
     ]
    }
   ],
   "source": [
    "print(train[['Garage Area', 'Gr Liv Area', 'Overall Cond', 'SalePrice']].corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation between `Gr Liv Area` and `SalePrice` is around 0.709, which is the highest. \n",
    "\n",
    "Let's now move on to understanding the model fitting criteria.\n",
    "\n",
    "**Residual Sum Of Squares**\n",
    "\n",
    "To find the optimal parameters for a linear regression model, we want to optimize the model's residual sum of squares (or RSS). If you recall, residual describes the difference between the predicted values for the target column and the true values. \n",
    "\n",
    "Let's now use scikit-learn to find the optimal parameter values for our model.  The `LinearRegression` class also has it's own `fit()` method. Specific to this model, however, are the `coef_` and `intercept_` attributes, which return a (or a(s) if it were a multivariate regression model) and b accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[116.86624683]\n",
      "5366.821710056043\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(train[['Gr Liv Area']], train['SalePrice'])\n",
    "print(lr.coef_)\n",
    "print(lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56034.362001412796\n",
      "57088.25161263909\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "train_preds = lr.predict(train[['Gr Liv Area']])\n",
    "test_preds = lr.predict(test[['Gr Liv Area']])\n",
    "\n",
    "train_mse = mean_squared_error(train['SalePrice'], train_preds)\n",
    "test_mse = mean_squared_error(test['SalePrice'], test_preds)\n",
    "\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "print(train_rmse)\n",
    "print(test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multivariate Linear Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56032.39801525867\n",
      "57066.90779448559\n"
     ]
    }
   ],
   "source": [
    "cols = ['Overall Cond', 'Gr Liv Area']\n",
    "\n",
    "lr.fit(train[cols], train['SalePrice'])\n",
    "\n",
    "train_preds = lr.predict(train[cols])\n",
    "test_preds = lr.predict(test[cols])\n",
    "\n",
    "train_mse = mean_squared_error(train['SalePrice'], train_preds)\n",
    "test_mse = mean_squared_error(test['SalePrice'], test_preds)\n",
    "\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "print(train_rmse)\n",
    "print(test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order              0\n",
      "MS SubClass        0\n",
      "Lot Area           0\n",
      "Overall Qual       0\n",
      "Overall Cond       0\n",
      "1st Flr SF         0\n",
      "2nd Flr SF         0\n",
      "Low Qual Fin SF    0\n",
      "Gr Liv Area        0\n",
      "Full Bath          0\n",
      "Half Bath          0\n",
      "Bedroom AbvGr      0\n",
      "Kitchen AbvGr      0\n",
      "TotRms AbvGrd      0\n",
      "Fireplaces         0\n",
      "Garage Cars        0\n",
      "Garage Area        0\n",
      "Wood Deck SF       0\n",
      "Open Porch SF      0\n",
      "Enclosed Porch     0\n",
      "3Ssn Porch         0\n",
      "Screen Porch       0\n",
      "Pool Area          0\n",
      "Misc Val           0\n",
      "SalePrice          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Select the integer and float columns from train\n",
    "numerical_train = train.select_dtypes(include=['int64', 'float64'])\n",
    "numerical_train = numerical_train.drop(['PID', 'Year Built', 'Year Remod/Add', 'Garage Yr Blt', 'Mo Sold', 'Yr Sold'], axis=1)\n",
    "null_series = numerical_train.isnull().sum()\n",
    "full_cols_series = null_series[null_series == 0]\n",
    "print(full_cols_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misc Val           0.009903\n",
      "3Ssn Porch         0.038699\n",
      "Low Qual Fin SF    0.060352\n",
      "Order              0.068181\n",
      "MS SubClass        0.088504\n",
      "Overall Cond       0.099395\n",
      "Screen Porch       0.100121\n",
      "Bedroom AbvGr      0.106941\n",
      "Kitchen AbvGr      0.130843\n",
      "Pool Area          0.145474\n",
      "Enclosed Porch     0.165873\n",
      "2nd Flr SF         0.202352\n",
      "Half Bath          0.272870\n",
      "Lot Area           0.274730\n",
      "Wood Deck SF       0.319104\n",
      "Open Porch SF      0.344383\n",
      "TotRms AbvGrd      0.483701\n",
      "Fireplaces         0.485683\n",
      "Full Bath          0.518194\n",
      "1st Flr SF         0.657119\n",
      "Garage Area        0.662397\n",
      "Garage Cars        0.663485\n",
      "Gr Liv Area        0.698990\n",
      "Overall Qual       0.804562\n",
      "SalePrice          1.000000\n",
      "Name: SalePrice, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Compute the pairwise correlation coefficients between all of the columns\n",
    "train_subset = train[full_cols_series.index]\n",
    "corrmat = train_subset.corr()\n",
    "# Select just the SalePrice column from the resulting data frame,\n",
    "# compute the absolute value of each term, sort the resulting Series by the correlation values, and assign to sorted_corrs.\n",
    "sorted_corr = corrmat['SalePrice'].abs().sort_values()\n",
    "print(sorted_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, let's keep only the features that have a correlation of 0.3 or higher. \n",
    "\n",
    "#### Checking for collinearity\n",
    "\n",
    "The next thing we need to look for is for potential **collinearity** between some of these feature columns. Collinearity is when 2 feature columns are highly correlated and stand the risk of duplicating information. If we have 2 features that convey the same information using 2 different measures or metrics, we don't need to keep both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22f1de1c1d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "strong_corrs = sorted_corr[sorted_corr > 0.3]\n",
    "corrmat = train_subset[strong_corrs.index].corr()\n",
    "sns.heatmap(corrmat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the correlation matrix heatmap, we can tell that the following pairs of columns are strongly correlated:\n",
    "* `Gr Liv Area` and `TotRms AbvGrd`\n",
    "* `Garage Area` and `Garage Cars`\n",
    "\n",
    "Let's drop the `TotRms AbvGrd` and `Garage Cars`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1470 entries, 1460 to 2929\n",
      "Data columns (total 9 columns):\n",
      "Wood Deck SF     1470 non-null int64\n",
      "Open Porch SF    1470 non-null int64\n",
      "Fireplaces       1470 non-null int64\n",
      "Full Bath        1470 non-null int64\n",
      "1st Flr SF       1470 non-null int64\n",
      "Garage Area      1469 non-null float64\n",
      "Gr Liv Area      1470 non-null int64\n",
      "Overall Qual     1470 non-null int64\n",
      "SalePrice        1470 non-null int64\n",
      "dtypes: float64(1), int64(8)\n",
      "memory usage: 103.4 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "final_corr_cols = strong_corrs.drop(['Garage Cars', 'TotRms AbvGrd'])\n",
    "print(test[final_corr_cols.index].info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the test set has one pesky row with a missing value for `Garage Area`. Let's just drop this row for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34173.97629185852\n",
      "41032.026120197705\n"
     ]
    }
   ],
   "source": [
    "final_corr_cols = strong_corrs.drop(['Garage Cars', 'TotRms AbvGrd'])\n",
    "features = final_corr_cols.drop(['SalePrice']).index\n",
    "target = 'SalePrice'\n",
    "clean_test = test[final_corr_cols.index].dropna()\n",
    "\n",
    "# build a lr model\n",
    "lr.fit(train[features], train['SalePrice'])\n",
    "\n",
    "train_preds = lr.predict(train[features])\n",
    "test_preds = lr.predict(clean_test[features])\n",
    "\n",
    "train_mse = mean_squared_error(train_preds, train[target])\n",
    "test_mse = mean_squared_error(test_preds, clean_test[target])\n",
    "\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "print(train_rmse)\n",
    "print(test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last technique we'll explore is removing features with low variance. When the values in a feature column have low variance, they don't meaningfully contribute to the model's predictive capability. On the extreme end, let's imagine a column with a variance of 0. This would mean that all of the values in that column were exactly the same. This means that the column isn't informative and isn't going to help the model make better predictions.\n",
    "\n",
    "To make apples to apples comparisons between columns, we need to rescale all of the columns to vary between 0 and 1. Then, we can set a cutoff value for variance and remove features that have less than that variance amount. This is known as **min-max scaling** or as **rescaling**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wood Deck SF     0.0\n",
      "Open Porch SF    0.0\n",
      "Fireplaces       0.0\n",
      "Full Bath        0.0\n",
      "1st Flr SF       0.0\n",
      "Garage Area      0.0\n",
      "Gr Liv Area      0.0\n",
      "Overall Qual     0.0\n",
      "dtype: float64\n",
      "Wood Deck SF     1.0\n",
      "Open Porch SF    1.0\n",
      "Fireplaces       1.0\n",
      "Full Bath        1.0\n",
      "1st Flr SF       1.0\n",
      "Garage Area      1.0\n",
      "Gr Liv Area      1.0\n",
      "Overall Qual     1.0\n",
      "dtype: float64\n",
      "Open Porch SF    0.013938\n",
      "Full Bath        0.018621\n",
      "Garage Area      0.020347\n",
      "Gr Liv Area      0.023078\n",
      "Overall Qual     0.024496\n",
      "1st Flr SF       0.025814\n",
      "Wood Deck SF     0.033064\n",
      "Fireplaces       0.046589\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# make a new dataframe with rescaled values\n",
    "unit_train = (train[features] - train[features].min())/(train[features].max()-train[features].min())\n",
    "# to confirm min and max are 0.0 and 1.0 respectively\n",
    "print(unit_train.min())\n",
    "print(unit_train.max())\n",
    "\n",
    "# to compare variance\n",
    "sorted_vars = unit_train.var().sort_values()\n",
    "print(sorted_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set a cutoff variance of 0.015, remove the `Open Porch SF` feature, and train and test a model using the remaining features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wood Deck SF</th>\n",
       "      <th>Open Porch SF</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>Full Bath</th>\n",
       "      <th>1st Flr SF</th>\n",
       "      <th>Garage Area</th>\n",
       "      <th>Gr Liv Area</th>\n",
       "      <th>Overall Qual</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>168</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1366</td>\n",
       "      <td>725.0</td>\n",
       "      <td>1947</td>\n",
       "      <td>9</td>\n",
       "      <td>274000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>182</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1786</td>\n",
       "      <td>715.0</td>\n",
       "      <td>1786</td>\n",
       "      <td>8</td>\n",
       "      <td>300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1149</td>\n",
       "      <td>779.0</td>\n",
       "      <td>2290</td>\n",
       "      <td>8</td>\n",
       "      <td>255900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>884</td>\n",
       "      <td>543.0</td>\n",
       "      <td>1768</td>\n",
       "      <td>7</td>\n",
       "      <td>224900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1129</td>\n",
       "      <td>596.0</td>\n",
       "      <td>2327</td>\n",
       "      <td>7</td>\n",
       "      <td>240000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Wood Deck SF  Open Porch SF  Fireplaces  Full Bath  1st Flr SF  \\\n",
       "1460           168            116           1          2        1366   \n",
       "1461           182             35           1          2        1786   \n",
       "1462             0              0           1          2        1149   \n",
       "1463             0             63           0          2         884   \n",
       "1464             0             57           1          2        1129   \n",
       "\n",
       "      Garage Area  Gr Liv Area  Overall Qual  SalePrice  \n",
       "1460        725.0         1947             9     274000  \n",
       "1461        715.0         1786             8     300000  \n",
       "1462        779.0         2290             8     255900  \n",
       "1463        543.0         1768             7     224900  \n",
       "1464        596.0         2327             7     240000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34372.696707783965\n",
      "40591.42702437721\n"
     ]
    }
   ],
   "source": [
    "clean_test = test[final_corr_cols.index].dropna()\n",
    "features = features.drop('Open Porch SF')\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(train[features], train['SalePrice'])\n",
    "\n",
    "train_predictions = lr.predict(train[features])\n",
    "test_predictions = lr.predict(clean_test[features])\n",
    "\n",
    "train_mse = mean_squared_error(train_predictions, train[target])\n",
    "test_mse = mean_squared_error(test_predictions, clean_test[target])\n",
    "\n",
    "train_rmse_2 = np.sqrt(train_mse)\n",
    "test_rmse_2 = np.sqrt(test_mse)\n",
    "\n",
    "print(train_rmse_2)\n",
    "print(test_rmse_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were able to improve the RMSE value to approximately 40591 by removing the `Open Porch SF` feature. This is most likely the furthest we can go without transforming and utilizing the other features in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent \n",
    "def derivative(a1, xi_list, yi_list):\n",
    "    len_data = len(xi_list)\n",
    "    error = 0\n",
    "    for i in range(0, len_data):\n",
    "        error += xi_list[i]*(a1*xi_list[i] - a1*yi_list[i])\n",
    "    deriv = 2*error/len_data\n",
    "    return deriv\n",
    "\n",
    "def gradient_descent(xi_list, yi_list, max_iterations, alpha, a1_initial):\n",
    "    a1_list = [a1_initial]\n",
    "    \n",
    "    for i in range(0, max_iterations):\n",
    "        a1 = a1_list[i]\n",
    "        deriv = derivative(a1, xi_list, yi_list)\n",
    "        a1_new = a1 - alpha*deriv\n",
    "        a1_list.append(a1_new)\n",
    "    return(a1_list)\n",
    "\n",
    "param_iterations = gradient_descent(train['Gr Liv Area'], train['SalePrice'], 20, .0000003, 150)\n",
    "final_param = param_iterations[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've understood how single parameter gradient descent works, let's build some intuition for multi parameter gradient descent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000, 999.9729797812329, 999.985903701066, 999.980232547139, 999.9832179015052, 999.9821734177915, 999.983004932363, 999.9829631191217, 999.9833278635107, 999.98350334434, 999.9837669324418, 999.9839895042135, 999.9842311701743, 999.9844639472566, 999.9847008623329, 999.9849358510428, 999.9851717365096, 999.9854072044933, 999.985642866808, 999.9858784386378, 999.986114052572]\n",
      "[150, 105.34801721547944, 126.13471917628125, 116.45794862200977, 120.96274606972909, 118.86564116059868, 119.84189984026605, 119.38742488614261, 119.59899502291616, 119.50050320781361, 119.54635359313434, 119.52500879150305, 119.53494516153384, 119.53031930255781, 119.53247255390217, 119.53146994657168, 119.53193647656232, 119.53171908350993, 119.53182007507831, 119.53177285001942, 119.53179462379771]\n"
     ]
    }
   ],
   "source": [
    "def a1_derivative(a0, a1, xi_list, yi_list):\n",
    "    len_data = len(xi_list)\n",
    "    error = 0\n",
    "    for i in range(0, len_data):\n",
    "        error += xi_list[i]*(a0 + a1*xi_list[i] - yi_list[i])\n",
    "    deriv = 2*error/len_data\n",
    "    return deriv\n",
    "\n",
    "def a0_derivative(a0, a1, xi_list, yi_list):\n",
    "    len_data = len(xi_list)\n",
    "    error = 0\n",
    "    for i in range(0, len_data):\n",
    "        error += a0 + a1*xi_list[i] - yi_list[i]\n",
    "    deriv = 2*error/len_data\n",
    "    return deriv\n",
    "\n",
    "def gradient_descent(xi_list, yi_list, max_iterations, alpha, a1_initial, a0_initial):\n",
    "    a1_list = [a1_initial]\n",
    "    a0_list = [a0_initial]\n",
    "\n",
    "    for i in range(0, max_iterations):\n",
    "        a1 = a1_list[i]\n",
    "        a0 = a0_list[i]\n",
    "        \n",
    "        a1_deriv = a1_derivative(a0, a1, xi_list, yi_list)\n",
    "        a0_deriv = a0_derivative(a0, a1, xi_list, yi_list)\n",
    "        \n",
    "        a1_new = a1 - alpha*a1_deriv\n",
    "        a0_new = a0 - alpha*a0_deriv\n",
    "        \n",
    "        a1_list.append(a1_new)\n",
    "        a0_list.append(a0_new)\n",
    "    return(a0_list, a1_list)\n",
    "\n",
    "a0_params, a1_params = gradient_descent(train['Gr Liv Area'], train['SalePrice'], 20, .0000003, 150, 1000)\n",
    "print(a0_params)\n",
    "print(a1_params)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike gradient descent, **ordinary least squares** (OLS) estimation provides a clear formula to directly calculate the optimal parameter values that minimize the cost function. \n",
    "\n",
    "Let's start by computing OLS estimation to find the best parameters for a model using the following features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   53.75693376 18232.31375751 -6434.65300989    22.53151963\n",
      "    86.81522574    28.08976713 11397.64135314]\n"
     ]
    }
   ],
   "source": [
    "features = ['Wood Deck SF', 'Fireplaces', 'Full Bath', '1st Flr SF', 'Garage Area',\n",
    "       'Gr Liv Area', 'Overall Qual']\n",
    "\n",
    "X = train[features]\n",
    "y = train['SalePrice']\n",
    "\n",
    "first_term = np.linalg.inv(np.dot(np.transpose(X), X))\n",
    "second_term = np.dot(np.transpose(X), y)\n",
    "\n",
    "ols_estimation = np.dot(first_term, second_term)\n",
    "print(ols_estimation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand how linear regression works, we've stuck to using features from the training dataset that contained no missing values and were already in a convenient numeric representation. In this mission, we'll explore how to transform some of the remaining features so we can use them in our model. Broadly, the process of processing and creating new features is known as **feature engineering**.\n",
    "\n",
    "Amongst the columns that don't contain missing values, some of the common issues include:\n",
    "\n",
    " * the column is not numerical (e.g. a zoning code represented using text)\n",
    " * the column is numerical but not ordinal (e.g. zip code values)\n",
    " * the column is numerical but isn't representative of the type of relationship with the target column (e.g. year values)\n",
    " \n",
    "Let's start by filtering the training set to just the columns containing no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_null_counts = train.isnull().sum()\n",
    "\n",
    "df_no_mv = train[train_null_counts[train_null_counts == 0].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AllPub    1457\n",
      "NoSewr       2\n",
      "NoSeWa       1\n",
      "Name: Utilities, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train['Utilities'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the columns in the data frame df_no_mv contain string values. If these columns contain only a limited set of uniuqe values, they're known as **categorical features**. As the name suggests, a categorical feature groups a specific training example into a specific category.\n",
    "\n",
    "To use these features in our model, we need to transform them into numerical representations. We can convert any column that contains no missing values (or an error will be thrown) to the categorical data type using the `pandas.Series.astype()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       AllPub\n",
      "1       AllPub\n",
      "2       AllPub\n",
      "3       AllPub\n",
      "4       AllPub\n",
      "5       AllPub\n",
      "6       AllPub\n",
      "7       AllPub\n",
      "8       AllPub\n",
      "9       AllPub\n",
      "10      AllPub\n",
      "11      AllPub\n",
      "12      AllPub\n",
      "13      AllPub\n",
      "14      AllPub\n",
      "15      AllPub\n",
      "16      AllPub\n",
      "17      AllPub\n",
      "18      AllPub\n",
      "19      AllPub\n",
      "20      AllPub\n",
      "21      AllPub\n",
      "22      AllPub\n",
      "23      AllPub\n",
      "24      AllPub\n",
      "25      AllPub\n",
      "26      AllPub\n",
      "27      AllPub\n",
      "28      AllPub\n",
      "29      AllPub\n",
      "         ...  \n",
      "1430    AllPub\n",
      "1431    AllPub\n",
      "1432    AllPub\n",
      "1433    AllPub\n",
      "1434    AllPub\n",
      "1435    AllPub\n",
      "1436    AllPub\n",
      "1437    AllPub\n",
      "1438    AllPub\n",
      "1439    AllPub\n",
      "1440    AllPub\n",
      "1441    AllPub\n",
      "1442    AllPub\n",
      "1443    AllPub\n",
      "1444    AllPub\n",
      "1445    AllPub\n",
      "1446    AllPub\n",
      "1447    AllPub\n",
      "1448    AllPub\n",
      "1449    AllPub\n",
      "1450    AllPub\n",
      "1451    AllPub\n",
      "1452    AllPub\n",
      "1453    AllPub\n",
      "1454    AllPub\n",
      "1455    AllPub\n",
      "1456    AllPub\n",
      "1457    AllPub\n",
      "1458    AllPub\n",
      "1459    AllPub\n",
      "Name: Utilities, Length: 1460, dtype: category\n",
      "Categories (3, object): [AllPub, NoSeWa, NoSewr]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vungu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train['Utilities'] = train['Utilities'].astype('category')\n",
    "print(train['Utilities'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a column is converted to the categorical data type, pandas assigns a code to each unique value in the column. Unless we access these values directly, most of the pandas manipulation operations that work for string columns will work for categorical ones as well.\n",
    "\n",
    "We need to use the `.cat` accessor followed by the `.codes` property to actually access the underlying numerical representation of a column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "5       0\n",
       "6       0\n",
       "7       0\n",
       "8       0\n",
       "9       0\n",
       "10      0\n",
       "11      0\n",
       "12      0\n",
       "13      0\n",
       "14      0\n",
       "15      0\n",
       "16      0\n",
       "17      0\n",
       "18      0\n",
       "19      0\n",
       "20      0\n",
       "21      0\n",
       "22      0\n",
       "23      0\n",
       "24      0\n",
       "25      0\n",
       "26      0\n",
       "27      0\n",
       "28      0\n",
       "29      0\n",
       "       ..\n",
       "1430    0\n",
       "1431    0\n",
       "1432    0\n",
       "1433    0\n",
       "1434    0\n",
       "1435    0\n",
       "1436    0\n",
       "1437    0\n",
       "1438    0\n",
       "1439    0\n",
       "1440    0\n",
       "1441    0\n",
       "1442    0\n",
       "1443    0\n",
       "1444    0\n",
       "1445    0\n",
       "1446    0\n",
       "1447    0\n",
       "1448    0\n",
       "1449    0\n",
       "1450    0\n",
       "1451    0\n",
       "1452    0\n",
       "1453    0\n",
       "1454    0\n",
       "1455    0\n",
       "1456    0\n",
       "1457    0\n",
       "1458    0\n",
       "1459    0\n",
       "Length: 1460, dtype: int8"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Utilities'].cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert all of the text columns that contain no missing values into the categorical data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS Zoning: 6\n",
      "Street: 2\n",
      "Lot Shape: 4\n",
      "Land Contour: 4\n",
      "Utilities: 3\n",
      "Lot Config: 5\n",
      "Land Slope: 3\n",
      "Neighborhood: 26\n",
      "Condition 1: 9\n",
      "Condition 2: 6\n",
      "Bldg Type: 5\n",
      "House Style: 8\n",
      "Roof Style: 6\n",
      "Roof Matl: 5\n",
      "Exterior 1st: 14\n",
      "Exterior 2nd: 16\n",
      "Exter Qual: 4\n",
      "Exter Cond: 5\n",
      "Foundation: 6\n",
      "Heating: 6\n",
      "Heating QC: 4\n",
      "Central Air: 2\n",
      "Electrical: 4\n",
      "Kitchen Qual: 5\n",
      "Functional: 7\n",
      "Paved Drive: 3\n",
      "Sale Type: 9\n",
      "Sale Condition: 5\n"
     ]
    }
   ],
   "source": [
    "text_cols = df_no_mv.select_dtypes(include=['object']).columns\n",
    "\n",
    "for col in text_cols:\n",
    "    print(col + ':', len(train[col].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vungu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AllPub    1457\n",
       "NoSewr       2\n",
       "NoSeWa       1\n",
       "Name: Utilities, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in text_cols:\n",
    "    train[col] = train[col].astype('category')\n",
    "train['Utilities'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we convert a column to the categorical data type, pandas assigns a number from 0 to n-1 (where n is the number of unique values in a column) for each value. **The drawback with this approach is that one of the assumptions of linear regression is violated here.//==** Linear regression operates under the assumption that the features are linearly correlated with the target column. For a categorical feature, however, there's no actual numerical meaning to the categorical codes that pandas assigned for that column. An increase in the Utilities column from 1 to 2 has no correlation value with the target column, and the categorical codes are instead used for uniqueness and exclusivity (the category associated with 0 is different than the one associated with 1).\n",
    "\n",
    "The common solution is to use a technique called `dummy coding`. Instead of having a single column with n integer codes, we have **n binary columns**.\n",
    "\n",
    "Because the original values for the first 4 rows were `AllPub`, in the new scheme, they contain the binary value for true (1) in the `Utilities_AllPub` column and 0 for the other 2 columns.\n",
    "\n",
    "Pandas thankfully has a convenience function to help us apply this transformation for all of the text columns called `pandas.get_dummies()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_cols = pd.DataFrame()\n",
    "for col in text_cols:\n",
    "    col_dummies = pd.get_dummies(train[col])\n",
    "    train = pd.concat([train, col_dummies],1)\n",
    "    del train[col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the numerical columns in the data set are also categorical and only have a limited set of unique values. We won't explicitly explore those columns in this mission, but the feature transformation process is the same if the numbers used in those categories have no numerical meaning.\n",
    "\n",
    "Let's now look at numerical features that aren't categorical, but whose numerical representation needs to be improved. We'll focus on the `Year Remod/Add` and `Year Built` columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Year Remod/Add  Year Built\n",
      "0               1960        1960\n",
      "1               1961        1961\n",
      "2               1958        1958\n",
      "3               1968        1968\n",
      "4               1998        1997\n",
      "5               1998        1998\n",
      "6               2001        2001\n",
      "7               1992        1992\n",
      "8               1996        1995\n",
      "9               1999        1999\n",
      "10              1994        1993\n",
      "11              2007        1992\n",
      "12              1998        1998\n",
      "13              1990        1990\n",
      "14              1985        1985\n",
      "15              2003        2003\n",
      "16              2005        1988\n",
      "17              2010        2010\n",
      "18              1951        1951\n",
      "19              1988        1978\n",
      "20              1977        1977\n",
      "21              1974        1974\n",
      "22              2000        2000\n",
      "23              1970        1970\n",
      "24              2008        1971\n",
      "25              1968        1968\n",
      "26              1970        1970\n",
      "27              1971        1971\n",
      "28              1999        1999\n",
      "29              1971        1971\n",
      "...              ...         ...\n",
      "1430            1997        1997\n",
      "1431            1994        1994\n",
      "1432            2006        1995\n",
      "1433            1995        1994\n",
      "1434            1998        1997\n",
      "1435            1997        1997\n",
      "1436            2000        2000\n",
      "1437            1999        1999\n",
      "1438            1999        1998\n",
      "1439            2000        1999\n",
      "1440            2002        2002\n",
      "1441            2001        2001\n",
      "1442            2001        2000\n",
      "1443            2002        2001\n",
      "1444            1980        1975\n",
      "1445            1977        1977\n",
      "1446            1978        1978\n",
      "1447            1978        1978\n",
      "1448            1975        1975\n",
      "1449            2001        1975\n",
      "1450            1975        1975\n",
      "1451            1972        1972\n",
      "1452            1972        1972\n",
      "1453            2002        2002\n",
      "1454            2002        2002\n",
      "1455            2000        2000\n",
      "1456            2001        2001\n",
      "1457            2000        1999\n",
      "1458            1999        1998\n",
      "1459            2002        2001\n",
      "\n",
      "[1460 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train[['Year Remod/Add', 'Year Built']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two main issues with these features are:\n",
    "\n",
    " * Year values aren't representative of how old a house is\n",
    " * The Year Remod/Add column doesn't actually provide useful information for a linear regression model\n",
    " \n",
    "The challenge with year values like 1960 and 1961 is that they don't do a good job of capturing how old a house is. For example, a house that was built in 1960 but sold in 1980 was sold in half the time as one built in 1960 and sold in 2000. Instead of the years certain events happened, we want the **difference** between those years. We should create a new column that's the difference between both of these columns.\n",
    "\n",
    "For this particular piece of information (years until remodeled), this is a sensible approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_until_remodeled = train['Year Remod/Add'] - train['Year Built']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll focus on handling columns with missing values. When values are missing in a column, there are two main approaches we can take:\n",
    "\n",
    "* Remove rows containing missing values for specific columns\n",
    " * Pro: Rows containing missing values are removed, leaving only clean data for modeling\n",
    " * Con: Entire observations from the training set are removed, which can reduce overall prediction accuracy\n",
    "\n",
    "* Impute (or replace) missing values using a descriptive statistic from the column\n",
    " * Pro: Missing values are replaced with potentially similar estimates, preserving the rest of the observation in the model.\n",
    " * Con: Depending on the approach, we may be adding noisy data for the model to learn\n",
    "\n",
    "Given that we only have 1460 training examples (with ~80 potentially useful features), we don't want to remove any of these rows from the dataset. Let's instead focus on **imputation** techniques.\n",
    "\n",
    "We'll focus on columns that contain at least 1 missing value but less than 365 missing values (or 25% of the number of rows in the training set). There's no strict threshold, and many people instead use a 50% cutoff (if half the values in a column are missing, it's automatically dropped). Having some domain knowledge can help with determining an acceptable cutoff value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lot Frontage      249\n",
      "Mas Vnr Type       11\n",
      "Mas Vnr Area       11\n",
      "Bsmt Qual          40\n",
      "Bsmt Cond          40\n",
      "Bsmt Exposure      41\n",
      "BsmtFin Type 1     40\n",
      "BsmtFin SF 1        1\n",
      "BsmtFin Type 2     41\n",
      "BsmtFin SF 2        1\n",
      "Bsmt Unf SF         1\n",
      "Total Bsmt SF       1\n",
      "Bsmt Full Bath      1\n",
      "Bsmt Half Bath      1\n",
      "Garage Type        74\n",
      "Garage Yr Blt      75\n",
      "Garage Finish      75\n",
      "Garage Qual        75\n",
      "Garage Cond        75\n",
      "dtype: int64\n",
      "Lot Frontage      float64\n",
      "Mas Vnr Type       object\n",
      "Mas Vnr Area      float64\n",
      "Bsmt Qual          object\n",
      "Bsmt Cond          object\n",
      "Bsmt Exposure      object\n",
      "BsmtFin Type 1     object\n",
      "BsmtFin SF 1      float64\n",
      "BsmtFin Type 2     object\n",
      "BsmtFin SF 2      float64\n",
      "Bsmt Unf SF       float64\n",
      "Total Bsmt SF     float64\n",
      "Bsmt Full Bath    float64\n",
      "Bsmt Half Bath    float64\n",
      "Garage Type        object\n",
      "Garage Yr Blt     float64\n",
      "Garage Finish      object\n",
      "Garage Qual        object\n",
      "Garage Cond        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "train = df[0:1460]\n",
    "test = df[1460:]\n",
    "\n",
    "train_null_counts = train.isnull().sum()\n",
    "df_missing_values = train[train_null_counts[(train_null_counts > 0) & (train_null_counts < 584)].index]\n",
    "\n",
    "print(df_missing_values.isnull().sum())\n",
    "print(df_missing_values.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like about half of the columns in `df_missing_values` are string columns (`object` data type), while about half are `float64` columns. For numerical columns with missing values, a common strategy is to compute the mean, median, or mode of each column and replace all missing values in that column with that value.\n",
    "\n",
    "Because imputation is a common task, pandas contains a `pandas.DataFrame.fillna()` method that we can use for this. If we pass in a value, all of the missing values (NaN) in the data frame are replaced by that value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lot Frontage      0\n",
      "Mas Vnr Area      0\n",
      "BsmtFin SF 1      0\n",
      "BsmtFin SF 2      0\n",
      "Bsmt Unf SF       0\n",
      "Total Bsmt SF     0\n",
      "Bsmt Full Bath    0\n",
      "Bsmt Half Bath    0\n",
      "Garage Yr Blt     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# only select float columns\n",
    "missing_floats = df_missing_values.select_dtypes(include=['float'])\n",
    "\n",
    "# return a new df\n",
    "float_cols = missing_floats.fillna(missing_floats.mean())\n",
    "\n",
    "print(float_cols.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
