{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boost Model\n",
    "\n",
    "We'll use the European Social Survey Data, but now with a categorical outcome: Whether or not someone lives with a partner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cntry</th>\n",
       "      <th>idno</th>\n",
       "      <th>year</th>\n",
       "      <th>tvtot</th>\n",
       "      <th>ppltrst</th>\n",
       "      <th>pplfair</th>\n",
       "      <th>pplhlp</th>\n",
       "      <th>happy</th>\n",
       "      <th>sclmeet</th>\n",
       "      <th>sclact</th>\n",
       "      <th>gndr</th>\n",
       "      <th>agea</th>\n",
       "      <th>partner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CH</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CH</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CH</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CH</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CH</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cntry  idno  year  tvtot  ppltrst  pplfair  pplhlp  happy  sclmeet  sclact  \\\n",
       "0    CH   5.0     6    3.0      3.0     10.0     5.0    8.0      5.0     4.0   \n",
       "1    CH  25.0     6    6.0      5.0      7.0     5.0    9.0      3.0     2.0   \n",
       "2    CH  26.0     6    1.0      8.0      8.0     8.0    7.0      6.0     3.0   \n",
       "3    CH  28.0     6    4.0      6.0      6.0     7.0   10.0      6.0     2.0   \n",
       "4    CH  29.0     6    5.0      6.0      7.0     5.0    8.0      7.0     2.0   \n",
       "\n",
       "   gndr  agea  partner  \n",
       "0   2.0  60.0      1.0  \n",
       "1   2.0  59.0      1.0  \n",
       "2   1.0  24.0      2.0  \n",
       "3   2.0  64.0      1.0  \n",
       "4   2.0  55.0      1.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv((\n",
    "    \"https://raw.githubusercontent.com/Thinkful-Ed/data-201-resources/\"\n",
    "    \"master/ESS_practice_data/ESSdata_Thinkful.csv\")).dropna()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definine outcome and predictors.\n",
    "# Set our outcome to 0 and 1.\n",
    "y = df['partner'] - 1\n",
    "X = df.loc[:, ~df.columns.isin(['partner', 'cntry', 'idno'])]\n",
    "\n",
    "# make the categorical variable 'country' into dummies\n",
    "X = pd.concat([X, pd.get_dummies(df.cntry)], axis=1)\n",
    "\n",
    "# .shape[0] is the total number of rows\n",
    "# create testing and training set\n",
    "offset = int(X.shape[0] * 0.9)\n",
    "\n",
    "# put 90% of the data in the training set\n",
    "X_train, y_train = X[:offset], y[:offset]\n",
    "\n",
    "# put 10% in the test set\n",
    "X_test, y_test = X[offset:], y[offset:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're now working with a binary outcome, we've switched to a classifier. Now our loss function can't be the residuals. Our options are \"deviance\", or \"exponential\". Deviance is used for logistic regression, and we'll try that here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent type I errors:0.04650845608292417\n",
      "Percent type II errors:0.17607746863066012\n",
      "Test set accurayc:\n",
      "Percent type I errors:0.06257668711656442\n",
      "Percent type II errors:0.18527607361963191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we'll make 500 iterations, use 2-deep trees, and set our loss function\n",
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 2,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "# initialize and fit model\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "\n",
    "# accuracy tables\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent type I errors:{}\\n'\n",
    "    'Percent type II errors:{}\\n'\n",
    "    'Test set accurayc:\\n'\n",
    "    'Percent type I errors:{}\\n'\n",
    "    'Percent type II errors:{}\\n'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partner</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>4167</td>\n",
       "      <td>341</td>\n",
       "      <td>4508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>1291</td>\n",
       "      <td>1533</td>\n",
       "      <td>2824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>5458</td>\n",
       "      <td>1874</td>\n",
       "      <td>7332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0     0.0   1.0   All\n",
       "partner                  \n",
       "0.0      4167   341  4508\n",
       "1.0      1291  1533  2824\n",
       "All      5458  1874  7332"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partner</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>454</td>\n",
       "      <td>51</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>151</td>\n",
       "      <td>159</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>605</td>\n",
       "      <td>210</td>\n",
       "      <td>815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    0.0  1.0  All\n",
       "partner               \n",
       "0.0      454   51  505\n",
       "1.0      151  159  310\n",
       "All      605  210  815"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike decision trees, gradient boost solutions are not terribly easy to interpret on the surface. But they aren't quite a black box. We can get a measure of how important various features are by counting how many times a feature is used over the course of many decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance = clf.feature_importances_\n",
    "\n",
    "# make importances relative to max importance\n",
    "feature_importance = 100.0 * (feature_importance/feature_importance.max())\n",
    "# argsort returns the indices/index that would sort an array.\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + 0.5\n",
    "plt.subplot(1,2,2)\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, X.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.71891856e-01, 3.02959385e+00, 1.41563989e+00, 1.70063921e+00,\n",
       "       1.23082274e+00, 1.65013912e+01, 4.19881458e+00, 1.38297465e+00,\n",
       "       5.11407664e+00, 1.00000000e+02, 3.53378101e-01, 5.32879423e-01,\n",
       "       7.26665721e-02, 2.03125711e+00, 5.55388239e-01, 2.19071330e-01])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 15,  0, 10, 11, 14,  4,  7,  2,  3, 13,  1,  6,  8,  5,  9],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_idx.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5,  1.5,  2.5,  3.5,  4.5,  5.5,  6.5,  7.5,  8.5,  9.5, 10.5,\n",
       "       11.5, 12.5, 13.5, 14.5, 15.5])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that age and happiness are the most important features in predicting whether or not someone lives with a partner.\n",
    "\n",
    "### Improve this gradient boost model\n",
    "\n",
    "While this model is already doing alright, we've seen from the Type I and Type II error rates that there is definitely room for improvement.  Let's see how low we can get the error rates to go in the test set, based on our model in the training set.  Strategies we use include:\n",
    "\n",
    "* More iterations\n",
    "* Trying a different loss function\n",
    "* Changing the structure of the weak learner: Allowing more leaves in the tree, or other modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cntry</th>\n",
       "      <th>idno</th>\n",
       "      <th>year</th>\n",
       "      <th>tvtot</th>\n",
       "      <th>ppltrst</th>\n",
       "      <th>pplfair</th>\n",
       "      <th>pplhlp</th>\n",
       "      <th>happy</th>\n",
       "      <th>sclmeet</th>\n",
       "      <th>sclact</th>\n",
       "      <th>gndr</th>\n",
       "      <th>agea</th>\n",
       "      <th>partner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CH</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CH</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CH</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CH</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CH</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cntry  idno  year  tvtot  ppltrst  pplfair  pplhlp  happy  sclmeet  sclact  \\\n",
       "0    CH   5.0     6    3.0      3.0     10.0     5.0    8.0      5.0     4.0   \n",
       "1    CH  25.0     6    6.0      5.0      7.0     5.0    9.0      3.0     2.0   \n",
       "2    CH  26.0     6    1.0      8.0      8.0     8.0    7.0      6.0     3.0   \n",
       "3    CH  28.0     6    4.0      6.0      6.0     7.0   10.0      6.0     2.0   \n",
       "4    CH  29.0     6    5.0      6.0      7.0     5.0    8.0      7.0     2.0   \n",
       "\n",
       "   gndr  agea  partner  \n",
       "0   2.0  60.0      1.0  \n",
       "1   2.0  59.0      1.0  \n",
       "2   1.0  24.0      2.0  \n",
       "3   2.0  64.0      1.0  \n",
       "4   2.0  55.0      1.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross_validation accuracy:[0.72017673 0.73588611 0.72238586 0.72042219 0.72238586 0.72238586\n",
      " 0.72631321 0.7317133  0.72778596 0.71502209]\n",
      "Percent type I errors:0.01282051282051282\n",
      "Percent type II errors:0.08496999454446263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# we'll make 1000 iterations, use 4 max-depth deep trees, and set our loss function to exponential\n",
    "params = {'n_estimators': 1000,\n",
    "          'max_depth': 4,\n",
    "          'loss': 'exponential'}\n",
    "\n",
    "# initialize and fit model\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X, y)\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.5, random_state=None)\n",
    "scores = cross_val_score(clf, X, y, cv=cv)\n",
    "\n",
    "y_preds = clf.predict(X)\n",
    "\n",
    "# accuracy tables\n",
    "table = pd.crosstab(y, y_preds, margins=True)\n",
    "\n",
    "tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "\n",
    "print(('Cross_validation accuracy:{}\\n'\n",
    "    'Percent type I errors:{}\\n'\n",
    "    'Percent type II errors:{}\\n'\n",
    ").format(scores, tI_errors, tII_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANwAAAEXCAYAAADGAipCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3WlcVVX78PHfYRBnAhJvxaw0xSnHFBW1wBQUEBQjtbBMvXOuOzWxcEokBYecgvw7VKaRGuI8JWk5m6JmOfU4gQOoKDLKcNbzwo+nCBWVM3G8vm+CffZw7S1Xa+29rr2ORimlEEIYhZWpAxDiaSIJJ4QRScIJYUSScEIYkSScEEYkCSeEEUnCPYHg4GAWLFhQZPnixYsZPHjwY+1r9uzZxMXFPXSd2NhY3n///QfGsnnz5sc6ZkhICIsWLXqsbfQhMTGR4cOHG/245kQS7gn06dOHH3/8scjyFStW8NZbbz3Wvj744AMCAgL0FZpZu3z5MufOnTN1GCZlY+oASqNOnToRHh7Ob7/9xiuvvALAgQMHUErh7u6OVqslPDyco0ePkpmZiVKKsLAwWrRoQUhICLdu3SIxMZHXXnuNGzduUKdOHfr378+qVav44YcfyMvLIy0tjYEDB9KnTx8Arl27Rv/+/UlJScHFxYXJkydTpUqVQnEdPnyY6dOnk52djZWVFcOGDcPDw+Oh5xIcHEzDhg05cuQIqampBAUFcf36dQ4cOEB2djZffPEFrq6uBAcH06BBAw4dOsTNmzfx9/dnxIgRAPz000/MmzcPrVZLhQoVGDt2LI0bN2bu3LkcOXKElJQU6tSpw++//05ycjL9+/dn0aJFREdHs337dnJycsjOzmbMmDF06tSJuXPncunSJa5du8alS5eoWrUqkZGRODs7c+7cOcaPH09qaipWVlYMHjyYrl27kpyczGeffcaVK1fIy8vDx8eHQYMGGeBfv4SUeCJz5sxRY8aM0f3+0Ucfqa+//loppdThw4fV8OHDVUFBgVJKqa+++kq9//77SimlxowZo9555x3ddmPGjFELFy5UGRkZKigoSKWmpiqllEpISFBNmzZVSin1448/qqZNm6rz588rpZSaMWOG+uCDD5RSSr399ttq06ZN6tatW6pz584qMTFRKaXU1atXVYcOHdSlS5eKxH7vmPe2HzZsmFJKqSNHjqi6deuq7du3K6WUmjJligoNDdWtN3DgQJWbm6vS0tKUl5eXio+PV3/99Zdq27atunjxolJKqT179ih3d3eVnp6u5syZo7y8vFReXp5SSql9+/YpHx8fpZRSSUlJKjg4WGVnZyullFq/fr3y9fXVXduOHTuq9PR0pZRS77//vpo9e7ZSSqmAgAD13XffKaWUunz5sm694OBgXdw5OTkqODhYbdiw4ZH+LY1JWrgnFBQUhI+PDxkZGeTn57Nr1y4mTpwIQLNmzbC3tycmJobExET2799PhQoVdNu2aNGiyP4qVKhAdHQ0O3fu5Pz585w8eZKsrCzd523btuX5558HoGfPnvTs2bPQ9keOHOHatWsMHTpUt0yj0XDq1CmqV6/+0HPp1KkTAM899xwA7du3B6BmzZocOHBAt96bb76Jra0ttra2eHt7s2vXLmrVqkXr1q1127Zp0wZHR0eOHz8OQNOmTbGxKfpn5uLiQkREBOvWrePChQu63sA9rVq1omLFigA0aNCAtLQ0bt26xcmTJ3njjTcAqFatGj/99BNZWVkcPHiQtLQ0Zs+eDUBWVhYnT56ka9euDz13Y5OEe0JVq1albdu2bNy4kaysLLy8vKhUqRIAO3bsYMqUKfTr14+OHTtSq1Yt1q5dq9u2fPnyRfZ39epV3nzzTYKCgmjRogXe3t78/PPPus+tra11P2u12iJ/xAUFBdSuXZuVK1fqliUnJ+Po6FjsuZQpU6bQ77a2tvdd75/HVEphZWWFVqtFo9EUWk8pRX5+PnD/cwX4448/GDJkCO+++y7u7u60bNmSSZMm6T4vW7as7meNRoNSSnf8fx7v7NmzVKlSBaUUMTExlCtXDoDU1FTs7OyKPXdjk4cmJfDWW2+xbt064uLiCj0s2b17Nx4eHvTp04dGjRrx008/UVBQ8NB9HT9+HEdHR4YMGUK7du10yXZvu/3793P58mUAYmJi6NChQ6HtmzZtyoULFzh48CAAJ06cwMvLi+TkZL2d79q1a9FqtaSlpbFp0yY8PT1p06YNu3btIjExEYC9e/dy5coVmjRpUmR7a2tr8vLyADh48CCNGjWiX79+tGrViu3btxd7jSpWrEjDhg11T3WvXLlC7969ycnJoWnTpixZsgSA27dv07t3b7Zv3663c9cXaeFKwM3NjbCwMOzt7XF1ddUt79WrFyNHjsTPz4/8/Hzc3d3ZunUrWq32gftyd3dn1apVeHt7o9FoaNWqFY6Ojly4cAGAunXr8sknn3D9+nVq1arFZ599Vmh7R0dH5syZQ0REBHfu3EEpRUREBDVq1NDb+ebk5NCzZ08yMzPp06cPbdq0AWDChAkMGzaMgoICypYtS3R0tK61/6eXXnoJOzs7evbsSXR0NFu3bqVLly5otVo8PDxIS0sjIyPjoTHMmDGDSZMmsXTpUjQaDVOmTKFKlSpMnz6dyZMn4+fnR25uLr6+vnTr1k1v564vGqXk9RxRvODgYN566y28vb1NHUqpJl1KIYxIWjghjEhaOCGMSBJOCCOShBPCiCThhDAiix+Hu3kzE61Wngvdj5NTRW7cePi419PuQdfIykqDg0OF+2zxcBafcFqtkoR7CLk2xdPnNZIupRBGJAknhBFJwglhRJJwQhiRJJwQRiQJJ4QRScIJYUTytoAQD5GbV0Darawiy62sNDg5VXzs/Vn8wHf/sK2k3Mw2dRiilFo3w1+v+5MupRBGZJAWLj8/n4kTJ3LmzBmuX7+Oq6srM2fOZMWKFXz33XdUqlSJWrVqUbNmTYYPH84vv/zCnDlzyM/Pp0aNGkyePBkHBwc2bdrEkiVLyMnJITc3l/DwcJo3b26IkIUwCoO0cAkJCdja2vLDDz+wbds20tPTWbhwIcuWLSM2Npbly5frJsdJTU1lxowZLFq0iLi4ONq1a8f06dPRarXExMQQHR3N2rVrGTBgwH3n8xeiNDFIC9eyZUueeeYZli1bxtmzZzl//jxubm54eHjoJvf08fHh9u3bHD16lCtXrtC3b1/g7pyL9vb2WFlZMX/+fOLj4zl37hwHDhzAykp6wML4qlQpOgPZkzJIwm3fvp05c+bQt29fevTowc2bN6lUqRK3b98usm5BQQHNmzcnOjoagDt37pCZmUlmZiY9e/akW7dutGzZEldXV5YtW2aIcIV4qGvX0osse9KnlAZpMvbu3UuXLl0IDAykcuXK7N+/H4CdO3eSkZFBbm4uW7duRaPR0KRJE44cOaL7VpUvv/ySiIgIzp8/j0ajYdCgQbi5ubFt27ZiJwoVwtwZpIV74403GDVqFBs2bMDW1pbmzZuTmppK3759efPNNylfvjwODg7Y2dlRpUoVwsPD+fDDD9FqtbpvSqlcuTL169enS5cuaDQa2rVrx6FDhwwRrhBGY7SB73PnzrFz507effddAAYPHswbb7yBp6enQY8r43CiJNbN8Ndrl9JoA98uLi78/vvv+Pr66lqs4r67TB8WhXY2+DGE5crN0+9tjMWXdt24kSHTCDxAlSqV7vt/b/G3B10js2/hTOVJLkpJ5dzJJ/22dGNFURafcKa4h1s3wx9pN8T9lHhYYP/+/QQHB+sjFiEsnpRuCGFEekm41NRUBg4ciJeXF4MGDSI3N5dZs2YRFBSEl5cXwcHBXL9+Hbj7HdDjx4/Hz8+PXr16kZSUBICnpycREREEBAQQEBDAn3/+yYULF3jttdd0X2S4f/9+BgwYoI+QhTAJvdzDXb58mejoaFxcXAgKCuL777/n7NmzxMTEYGVlxccff8zatWt57733SE1NpVmzZnz22WcsXbqUsLAwXVlX+fLliYuLIz4+njFjxrBu3Tpq1KjB/v37adOmDXFxcfTo0UMfIRucPuvvDKm0xGlKZldLWa9ePZ577jkAateuTeXKlRkzZgwrV67k3LlzHDlyhJo1awJgZ2dHQEAAAN27d2fmzJm6/QQFBQF3W7uQkBBSU1MJDAxk7dq1NG3alH379jFx4kR9hGxwpeFxuwwLFE/fwwJ66VLa2PydtxqNhps3b9K/f3+0Wi1eXl68/vrr3Bvus7KyQqPRAHffDLC2tr7vfu595u3tze7du9myZQsdOnTAzs5OHyELYRIGeWhy70vhe/fuzQsvvMCOHTt0hcfZ2dnEx8cDEBsbS4cOHXTbbdiwAYBt27ZRu3Zt7O3tKVeuHB06dGDmzJmlpjspxIMYZBwuJyeHkydP4ufnB0CjRo10D0cANm/ezKxZs3B2dmbatGm65YcPH2bVqlWUK1eOqVOn6pb7+Phw+PBhmjRpYohwhTAao5d2ubq6curUqSLLPT09+fbbb6lRo0ah5QUFBcyaNQsnJyf69etnrDBLpLRUmsg9XPGeutKuwMBAHBwciIqKeqLtpZZSmBMpXn6KSQtXvKeuhSspfRUvl5ZuojBvBk+49PR0QkJCmD9//n0///nnnzl//vxD788SExOJiooiPDz8sY+vr+JlKUgW+mDwhEtLS+PEiRMP/Pz48ePF7uPy5cskJibqMywhTMLgxcthYWGkpKQwdOhQFi9erFs+fPhwoqKiiImJISYmhh9//JHs7GxGjhyJr68vfn5+xMXF6fZx/PhxJk2aZOhwhTAogydcaGgozs7ODB06lPXr1wOQkZFBQkIC/fv3p1evXvTq1YvAwEDmzp2Lg4MD69ev55tvvmHu3LmcPHmS0NBQGjVqxIQJEwwdrhAGZbSHJg0aNCA3N5cLFy6QkJCAp6cnZcqUKbTOvn37dPdpjo6OdOzYkQMHDuDq6mqsMB/KEgt9LfGc9M3sipcfVbdu3di4cSMJCQn897//LfL5v0colFJmNRelpT1Cl2GB4pll8fLD2NjYkJ+fD4Cfnx8bN27kwoULtGjRAgBra2vd561bt2bVqlXA3Xfstm/fTqtWrQqtI0RpZvCEc3Jyonr16gQHB1OtWjUcHBzw9vbWvTHQsmVL1q1bx9KlSxk6dCi3bt3Cz8+Pt99+m0GDBtGwYUNq165Neno6o0ePNnS4QhiUxVea6HMcztK6X9KlLJ5UmjwmfU0Em3NHurSi5Cw+4aSWUpgTi0+4ktRSSv2k0DeLT7iS3MNJ/aTQN6PPS3lvEDsjI4MePXrg6+ur+264f/v999/59NNPjRmeEAZlshbuxIkTlClThtjY2Aeu8/LLL/Pyyy8bMSohDKvECbd//36+/PJLbGxsSEpKonHjxgwePJgPPviAWrVq8ddff1G9enUiIyN55plnALhx4waffPIJ169fZ9CgQUyfPp1PPvmE5ORkUlJSaNOmDVOmTOHAgQPMmzePpUuXEhwcjL29PWfOnOGLL76gfv36JT55IYxNLy1cQkICcXFxvPjii3zwwQfs3LmT06dPExoaipubG1OnTmXevHmEhoYCdwfDw8LCmDdvHtHR0axfv5769eszZ84ccnNz8fHx4Y8//ihyHFdXV+bNm6ePkB+ZpdcaWvr56YPZ1VK2bNmSWrVqAeDv78+KFSt44YUXcHNzAyAgIIBRo0Y9cHtfX1+OHTvG119/zdmzZ7l16xZZWVlF1mvcuLE+wn0sljwwLAPfxTPLge9/TuaqlMLa2rrQpK73lj3I0qVL2bJlC0FBQbRt25bTp08XKWQGKFu2rD7CFcJk9PKU8tChQyQnJ6PVaomLi6NDhw6cO3dO96b3jz/+WGjC13/bvXs3b775Jt26dePOnTucPHlS9wUeQlgSvbRwzs7OfPzxxyQnJ+Pu7k7btm2xt7dnzpw5XLx4EVdXV8LCwh64/TvvvMPEiRNZsGABFStWpFmzZiQlJem+j0AIS1Hi4uX9+/frniTek5SURN++fXVTmpdWll5pIvdwxTPLezhzJrWUwpxY/Os5knAPJi1c8aSFe0xPWrxs6d1JYRpGT7h7X+Zx7NgxtmzZ8shvcRc3oeyDPGnxshQuC0MwevHyPX/99Rc3btx45PWLm1BWiNLAJLWUt2/fZs6cOWRlZREVFUXVqlVZvXo1t27dwsPDgzp16rBw4UKsra2pUaMGkZGRhSaUfdxWTghzoZcWLiEhgU8//ZTNmzdz584dXS1lnz592LBhA7Vr1y5UA1m5cmVGjBiBp6cngwcPBiA5OZnVq1fz0Ucf8cUXX7B48WJiY2NxcXHh7NmzugllJdlEaWYWtZRwd6LYe+VgHh4e9O7dm9dffx0vLy/q169f6BtUjeVpKOx9Gs6xpMyueLmktZRQuE4yNDSUkydPsnPnTkaPHs2wYcN081gak6U/MpdhgeKZ5USwT1JL+aDJXfPz8+ncuTMODg68//77+Pv7c+LEiUITygpRWukl4e7VUnbt2pWqVasWqqX08fEhNTVVd692T+PGjTl69CjTp08vtNzGxoYRI0bw3nvv0aNHD44ePcrAgQMLTSgrRGmlly7ls88+yzfffKP7PSkpiXLlyt33e7lPnToFwIsvvsi2bdt0y3v06KH72dfXF19f3yLbxsTE6CNcIUzG4itNnnQiWJn4VRiC1FI+xeShSfGklvIxSS2lMCcWn3BSSynMickmgp07dy5z584t8nlsbCwhISHGDksIozBZ8bIQTyOTFC/fc+zYMXr16kVycjI9evRg+PDhhT739PTE29ubPXv2ABAeHk6DBg1KGrIQJmOSiWDvuXHjBjExMWRkZODp6Um/fv2K7Lt8+fLExcURHx/PmDFjWLdunT5CfiRPQ53h03COJWV2tZRPWrzcvn17ypQpg6OjIw4ODqSlpRVZJygoCLjb2oWEhJCamoqjo6M+wi6WpT8yl2GB4pllLeWTFi//cx2NRnPfyV//uY5Wqy22CFoIc2YWE8E+zIYNGwDYtm0btWvXxt7eXh8hC2ESZjER7MMcPnyYVatWUa5cOaZOnaqPcIUwGbOeCNbT05Nvv/2WGjVqlGg/T+JpqDSRe7jiSWnXY5JaSmFOpHj5KSYtXPGkhXtMUrwszIleEi42NpYDBw4Y7KFGYmIiUVFRhIeHP/a2UrwszEmpqKW8fPkyiYmJpg5DiBJ7aAt39epVRo0aRVZWFlZWVoSGhpKVlcXUqVNRSlG9enVmzJhRaBtPT098fHzYvXs3NjY2DBkyhMWLF3PhwgXGjBlD165duX79OuPHj+fq1atoNBpGjhxJ27ZtyczM5LPPPuPMmTMUFBQwcOBAfH19CQsLIykpiUmTJjFhwgSDXhAhDOmhLdyqVat47bXXiI2NZcSIERw4cIBRo0Yxbdo01q1bR926dVm9enWR7Z599lliY2OpXbs2CxYsYPHixURGRrJgwQIApkyZQmBgILGxsURFRTF+/HgyMjKIioqiYcOGxMbGsmzZMqKjo0lMTCQ0NJRGjRpJsolS76EtXJs2bRg+fDgnTpzg1VdfpXnz5mzatIn69esDMHLkSODuPdw/3asqqV69Os7OztjY2FC9enVu374NwJ49ezh79ixz5swB7k6Nl5iYyJ49e8jJyeHHH38EICsrizNnzlChQgU9nvKjexoKe5+GcywpoxUvt2jRgg0bNrBjxw42btxIZmYmGo1G93l6ejqZmZlFtrO1tf37ADZFD6HVavnmm290r+ukpKTg5OSEVqslMjKShg0bAnD9+nXs7e05fPjwk51dCVn6I3MZFiieUYuXIyIiWLt2Ld27d2f8+PGcPn2aGzdu8NdffwGwcOFCvv/++8c+aOvWrVm+fDlw91t0/Pz8yM7OpnXr1rr9paSk0K1bN65cufLASWOFKG0e2sIFBwczcuRIYmNjsba2Ztq0aZQvX56PP/6YvLw8atasSUREBFu2bHmsg4aGhjJ+/Hj8/PyAu4ldsWJFhg0bxsSJE/H19aWgoIDRo0dTs2ZNKlWqRHp6OqNHjyYyMvLJz1YIE7P4SpOSjMNZendLupTFk0qTxyQTwQpzYvEJJ7WUwpxYfMI9SrMvdZPCWCw+4R7lHk7qJoWxGLWW8kkneU1PT2fo0KEGiEgI4yoVxctpaWm6+VGEKM300qV8kiLnTZs2sWTJEnJycsjNzSU8PJzmzZtz4sQJxo8fT05ODvb29kyfPp2wsDBSUlIYOnQo8+fP10fIQpiEXhLuXpHzgAED+OWXXzhw4ABff/01ixYton79+syYMYPVq1fraiK1Wi0xMTFER0fj6OjIqlWrWLBgAdHR0YwaNYpRo0bh4eHB8uXL+eabbwgNDaVv374GTbantabwaT3vx2F2E8E+bpGzlZUV8+fPJz4+nnPnznHgwAGsrKxITU3l2rVreHh4ANCnTx/g7qREhvY0DgDLwHfxzHLg+3GLnDMzM+nZsyfdunWjZcuWuLq6smzZMmxtbQttd+fOHVJSUgotE6I008tDk8ctcj5//jwajYZBgwbh5ubGtm3bKCgooFKlSlStWpVdu3YBsGbNGmbPno2NjY0ULwuLoJcW7nGLnOvVq0f9+vXp0qULGo2Gdu3acejQIQAiIyOZOHEikZGRODg4EBERgYODA9WrVyc4OLjQ/JdClDYWX7z8KJ7WShO5hyueWd7DmTOppRTmpFQMfAthKSy+hXtYs/+0diWF6ZhtwulrctmHFS9L0bIwNulSCmFEBm/hZsyYwZYtW3BwcKBKlSq6r6CqU6cOJ06cwMnJidmzZ/PMM88QFxdHVFQUFStWxMXFhfLlywN3J5dt3LgxJ06cYPny5Tg5ORk6bCEMwqAtXHx8PIcOHWL9+vUsWLCAP//8E4CTJ0/Sr18/1q9fT+XKlVm3bh3JyclMnz6dZcuW8cMPPxSZfq9Dhw5s2bJFkk2UagZt4fbs2UOXLl0oU6YMZcqU4fXXXwfAycmJBg0aAFCnTh3S0tJISEigWbNmPPvsswD4+fmxb98+3b6aNGlikBif9uLdp/38H4XZFS8/iJWVFVqttshyOzs73c8ajQallO6/usD+NYHsP7fRp6d54FcGvotn1IlgS6pt27Zs3bqV3NxcMjIy2LFjB5cvX77vui1atODIkSMkJyej1WrZuHGjIUMTwiQM2sK99tprJCQk0L17d+zt7XF2dn5gS/Xss88SGhrKu+++S7ly5XjppZcMGZoQJmHQhEtISOCFF15gw4YN5OXl8eabb9K+fXsGDhyoW2f48OG6n729vfH29i6yn/j4eEOGKYTRGLR4+datW4wcOZJr166hlCIgIID+/fsb6nCP7WmvNJF7uOLp+x7O4t8WkOLlB5OEK568LfCY/n1RnvZWTZiWxSfcv2sppX5SmJJJEy4pKQlvb29q165daHlQUBAtWrQgPDycW7duUVBQQNOmTfn000915V5ClEYmb+GcnZ1Zs2ZNkeVdunQhPDycZs2aodVqmTRpErNnz2bs2LEmiFII/TB5wj3I9evXycnJAe5WrAwbNoxLly6ZOCohSsbkCZeSkoK/v3+hZREREYwdO5bBgwfj7OyMm5sbHTt25LXXXtPLMaV+8G9yLYpXamopH8WDupSurq507tyZvXv3smfPHkJCQvDz8+PTTz8t8THlUfhdMixQvFJVS/mkzp8/z/z586lYsSKdOnViwoQJfP/996xcudLUoQlRImaZcI6Ojnz77bfs3btXt+zEiRO6qdOFKK1M3qW83z1cy5YtWbBgAZGRkYSGhmJra8uLL77IzJkzTRSlEPph8aVd/yaVJn+Te7jiSWnXY5JaSmFOzPIeTghLZfEt3D+bfelOClMzecJt3ryZBQsWkJ+fj1IKf39/BgwYQHBwMFevXi1UO/nss8+yaNGix9r/P4uXpXBZmJpJEy45OZlp06YRGxuLg4MDmZmZBAcH8+KLLwIQFhaGm5ubKUMUQq9MmnA3b94kLy9PVzNZoUIFpk6darAZuoQwNZMmXL169ejYsSOvv/469evXx83NDT8/P55//nkAQkNDC3Upvb29GTx4sKnCFaLEzGIcLjk5mV27drFr1y62b9/O9OnTWbp0KcOGDStxl/Lf93BCmJJJW7gdO3aQlZVF165dCQwMJDAwkBUrVrBq1SqDHVMGev8mA9/Fs6ji5bJlyzJjxgySkpIAUEpJzaSwaCZt4Vq3bs2wYcMYNGgQeXl5ALRv356hQ4fSv3//IvdwAEuXLqVy5cqmCFeIEjP5OFz37t3p3r17keVLly41QTRCGJbJE87QFoV21v2ccyffhJEI8RQknBQvC3Ni8Ql370mS1FEKc2Dxbwv0D9uK38g1lLWz+P+3iFLAZAmXlJSEq6sru3fvLrTc09OTpKQkMjMzmTRpEp06daJbt2706dOn0JQLQpRGJm3hbG1tGTduHBkZGYWWK6UYNGgQtra2bNiwgbVr1xIaGsro0aPZv3+/iaIVouRMmnDOzs60bduWadOmFVp+8OBBLl++zNixYylTpgwADRo0YPDgwXz55ZemCFUIvTD5jc29+SZ3796Nu7s7AKmpqTRq1AiNRlNo3ZYtWzJjxownPpZMelqUXJPiWdREsBUrVmTy5MmMGzeOtWvXAqDRaCgoKCiybl5eXpEkfBxSN1iY1FIWz6JqKe9p165doa5lkyZNOH78uK7c654jR47QqFEjU4QohF6YRcLB3a7lrl27SElJ4T//+Q8vvfQS4eHhuqQ7fvw4UVFRDBkyxMSRCvHkzCbh7nUt7yXYvHnzKFOmDL6+vnTt2pUpU6YQGRkpUy6IUs0sXkA1Bqk0KUru4YonE8E+JqmlFObEbLqUQjwNLL6Fk+JlYU4svoWT4mVhTiw+4YQwJwZPuNGjR7NixQrd78HBwRw9epR+/frRvXt3evfuzZ9//gnA6dOnCQ4OJjAwEA8PD77//nsA5s6dS//+/enatSvLly83dMhCGIzB+1mBgYHMnTuXoKAgLl26RGpqKp9//jnjx4+nQYMG/PXXXwwdOpQtW7awcuVKhgwZQps2bUhMTKRbt2707t0bgNzcXDZu3GjocIUwKIMnnJubG+PGjSPID8qEAAAOVUlEQVQpKYk1a9bQpUsXoqOjGTt2rG6drKwsbt68SUhICL/++itfffUVp0+fJisrS7dO48aNSxyLFOoWJdekeKWqeFmj0RAQEMCGDRvYtGkTX331FYsXL2bNmjW6da5evcozzzzDiBEjqFy5Mh4eHnTt2pX169fr1ilbtmyJY5FB3sJk4Lt4pbJ4uUePHsTExFCtWjVcXFx44YUXdAm3e/du3nrrLd3PI0aM4PXXX+eXX34BuO9bA0KUVkZ5Vl6tWjWqVaumm38yMjKSiRMnsnDhQmxtbZk1axYajYbhw4fTp08f7OzsqFevHi4uLrpZmYWwBAavpVRKkZKSQnBwMOvXr9e9wW0s977MY90Mf+k+/Yt0KYtX6mopt2zZwsSJE5k4caLRkw3+nghWJoEV5sDi3xaQ4uUHkxaueKWuhTM1qaUU5sTiS7ukllKYE5P/FWZkZDBjxgwOHjyItbU1lStXJiQkhOzsbCZPnlxo3dOnTzN16lT8/eWbTEXpZNKE02q1DBw4EDc3N+Li4rCxsWHfvn0MHDiQDRs2FBoc//rrr1m9ejXe3t4mjFiIkjFpwu3fv58rV64wYsQIrKzu9m5bt27N559/jlar1a3322+/ERUVxcqVK7GzszNVuEKUmEkT7s8//6RevXq6ZLvn1Vdf1f1848YNPvroI8LCwqhZs2aJjid1g0XJNSleqaqlfBgrK6uHtlharZZRo0bh4+NDp06dSnw8eQRemAwLFM+ihgUaNWrE8uXLUUoVmlF55syZtG3blgMHDpCbm8vIkSNNGKUQ+mPSYYFXXnkFJycn5s2bpytS/vXXX4mNjSU1NZWVK1cya9YsbGxM/jBVCL0w6V+yRqPhyy+/5PPPP8fX1xcbGxscHBxYsGABU6dOpaCggIEDBxbaplevXrqXUoUobSy+tOseqTQpSu7himdR93DGILWUwpxYfGmXEObE4hPOyakilSqXM3UYQgAmTriMjAwmTZqEr68v/v7+BAcH88cff5CUlISnp2eR9V1dXR/7GP3DtkrhsjAbJku4e3WU9vb2xMXFsWbNGoYOHcrAgQO5deuWqcISwqBM9r/+R62jFMKSmCzhHlZHmZSUREpKiryGIyyOyRKuuDpKZ2fnQq/nwJPdw90jRbr3J9eleBZRvPywOsrnn39e78eTAd6iZOC7eKVyItj7eVgd5UsvvWSqsIQwKJO1cA+ro6xcubKpwhLCoEw6QOXo6EhkZOR9P4uPjy+y7NSpU4YOSQiDsvhKk0WhnWUSWGE2LL4EQ4qXhTmx+BZOCHMiCSeEEZm0S5mUlIS3tze1a9cGICcnh+bNmzNy5EhycnIKfXZPUFCQ7vvkhChtTH4P98+KEqUUM2fOZMSIEURERNy32kSI0sysupT3vpTxzJkzZGRkmDocIfTO5C3cv5UpU4bnn3+eX3/99b4FzBEREY9VU/kk5TdPE6mlLJ5F1FI+jEajoWzZsnrpUsqwwINJLWXxLKaW8kFyc3M5d+5coenOhbAUZpVwWq2WuXPn0qRJkyLvyQlhCUzepfznfZpWq6V+/frMnDmT9PT0+97DtWzZktDQUFOEKkSJWfxEsHIP92ByD1c8i7+HE8KSScIJYUSScEIYkSScEEYkCSeEEUnCCWFEknBCGJEknBBGZPJKE0OzstIUv9JTTK5P8e53jZ70ull8pYkQ5kS6lEIYkSScEEYkCSeEEUnCCWFEknBCGJEknBBGJAknhBFJwglhRJJwQhiRRSbcunXr6Nq1K507d2bZsmWmDsdsBAcH4+Pjg7+/P/7+/hw9elSuFZCRkYGvry9JSUkA7NmzBz8/Pzp37sysWbN06504cYIePXrg5eXFp59+Sn7+E3zvoLIwV69eVR4eHurmzZsqMzNT+fn5qTNnzpg6LJPTarWqXbt2Ki8vT7dMrpVSR44cUb6+vqphw4YqMTFRZWdnq1dffVVdvHhR5eXlqffee0/t2LFDKaWUj4+PSkhIUEopNXbsWLVs2bLHPp7FtXB79uyhdevWPPPMM5QvXx4vLy82b95s6rBM7uzZswC89957dOvWje+++06uFbBixQomTJiAs7MzAMeOHeP555/nueeew8bGBj8/PzZv3sylS5fIycmhadOmAPTo0eOJrpXFvS2QkpJClSpVdL87Oztz7NgxE0ZkHm7fvk2bNm0YN24ceXl59O3bly5dujz112rKlCmFfr/f309ycnKR5VWqVCE5Ofmxj2dxLZxWq0Wj+fvVCaVUod+fVs2aNSMiIoJKlSrh6OhIz549mTNnjlyrf3nQ34++/q4sLuH+85//cO3aNd3v165d03UXnma//fYbe/fu1f2ulMLFxUWu1b886O/n38uvX7/+RNfK4hKubdu27N27l9TUVLKzs9m6dSsdOnQwdVgml56eTkREBHfu3CEjI4PVq1cTGRkp1+pfmjRpwrlz57hw4QIFBQWsX7+eDh064OLigp2dHYcOHQJgzZo1T3StLO4ermrVqvzvf/+jb9++5OXl0bNnTxo3bmzqsEzOw8ODo0ePEhAQgFarpU+fPrRo0UKu1b/Y2dkxdepUhg8fzp07d3j11Vfx9vYGYPr06YSGhpKRkUHDhg3p27fvY+9f3vgWwogsrksphDmThBPCiCThhDAiSTghjEgSTggjkoR7Qq6urvj5+eHv709AQABeXl4EBgby+++/F7ttcHBwsXV4iYmJDB8+HIDk5GR69eqll7jhbuypqal629+jWrly5VP7RsI9FjcOZ0zffPMNjo6Out8XLVpEWFgYP/zwQ4n3ffnyZc6dOwfcHVuMiYkp8T5N7dChQ9SpU8fUYZiUJJye5Ofnc+XKFezt7XXLoqKi2Lp1K1qtFhcXFyZMmEDVqlULbRcdHc327dvJyckhOzubMWPG4OnpSWhoKMnJyfTv359Jkybh5+fHb7/9hqenJ/Pnz6dRo0YAfPjhh7Rq1Yo+ffo80vH+KSkpiXfeeQd3d3eOHz9OQUEBI0aM4IcffuDs2bM0atSImTNncvnyZYKDg2nfvj1Hjx5FKcX48eN55ZVXyMvLY+rUqezduxdra2saN27M2LFjqVixIp6enjRu3JhTp07x0UcfER8fz+7duylbtixeXl6MHz+eGzducO3aNVxcXPjiiy9wcnLC09OT7t27s3fvXq5cuYK/vz8ffvghAKtWrWLJkiVYWVnh4ODAtGnTqFatGvHx8URFRZGXl0fZsmUZM2YMzZo1M8C/dAnp5aWip1DdunWVr6+v8vX1Ve7u7srT01NNnjxZXb9+XSml1OrVq9WHH36oe/8sJiZGDRgwQCml1Ntvv602bdqkkpKSVHBwsMrOzlZKKbV+/Xrl6+urlFJq3759ysfHRymlVGJiomratKlSSqnZs2erSZMmKaWUunXrlmrVqpW6ffv2Q493v9hv3LihEhMTVd26ddVPP/2klFJq/PjxysPDQ6Wnp6ucnBzl7u6uDh06pFtv7dq1SimlduzYodzd3VVubq6aPXu2GjZsmMrNzVUFBQUqJCREjRs3TimllIeHh5o3b57uuGPGjFELFy5USin19ddfq6+++kopdfddvQEDBqhFixbptps6dapS6u47ey+//LK6ePGiOnHihHJzc1OXL19WSim1ZMkSNW7cOHXu3Dnl6+urUlNTlVJKnT59Wrm7u6vMzMzH/4c1MGnhSuBel/KPP/7gv//9L25ubjg5OQHw888/8/vvvxMYGAjcrULPzs4utL2LiwsRERGsW7eOCxcucPToUTIzMx96zMDAQHr27ElISAjr16/H09OTSpUqPdLx7sfW1hZPT08AatasSbNmzahYsSJw99WUtLQ0nJ2dsbe3x8/PD4BXX30Va2trTp06xS+//ML//vc/bG1tgbv3p0OHDtXt/5VXXrnvcd955x1+++03lixZwvnz5zlz5gxNmjTRfd6xY0fgbnfaycmJtLQ0Dh48SLt27ahWrRoA7777LgDLli0jJSVF9zuARqPh4sWL1KtXr9hrYEyScHrQsGFDxo4dS0hICPXr16dGjRpotVoGDBhAnz59AMjNzSUtLa3Qdn/88QdDhgzh3Xffxd3dnZYtWzJp0qSHHsvFxYUGDRqwY8cOYmNj+eSTTwAe6Xj3Y2trW+g1k3uJ82/W1taFftdqtVhbWxd5bUWr1ZKXl6f7vXz58vfdX2RkJMeOHSMwMBA3Nzfy8/NR/6gytLOz0/2s0WhQSmFtbV3oWDk5OVy6dAmtVkubNm344osvdJ9duXLFLN98kKeUeuLr60vjxo35/PPPAWjXrh2rVq0iIyMDgNmzZ/Pxxx8X2ubgwYM0atSIfv360apVK7Zv305BQQFw9w/8n3+4/xQUFMT//d//kZ2dTYsWLR75eCWRmprKL7/8AkB8fDy2trbUrVuX9u3b8/3335OXl4dWq2XZsmW4u7vfdx/W1ta6eUB27drFO++8Q0BAAE5OTuzZs0d37g/i5ubG3r17SUlJASAmJobIyEjatGnD7t27+X//7/8BsHPnTrp160ZOTo6+Tl9vpIXTo3HjxtGtWzd+/fVX3njjDZKTkwkKCkKj0VCtWjWmTp1aaH1fX1+2bt1Kly5d0Gq1eHh4kJaWRkZGBi+99BJ2dnb07Nmz0EQ2AJ6enkyaNImBAwfqlj3K8UrCzs6ONWvWMH36dMqWLcv8+fOxtrZm8ODBTJs2jYCAAPLz82ncuDHjxo277z46dOigi2no0KFEREQwe/ZsbG1tad68ORcvXnxoDK6urowePZoBAwYAd9+6Dg8Pp2rVqnz22Wd89NFHKKWwsbEhKiqKChUq6O389UXeFhDFSkpKws/Pj4SEBFOHUupJl1III5IWTggjkhZOCCOShBPCiCThhDAiSTghjEgSTggjkoQTwoj+P1oct3Yp01w6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance = clf.feature_importances_\n",
    "\n",
    "# make importances relative to max importance\n",
    "feature_importance = 100.0 * (feature_importance/feature_importance.max())\n",
    "# argsort returns the indices/index that would sort an array.\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + 0.5\n",
    "plt.subplot(1,2,2)\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, X.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Error rates improve as we increase the iterations, deepen the tree to 16 leaves, and change the loss function to 'exponential'.\n",
    "\n",
    "\n",
    "# Neural Network Model\n",
    "\n",
    "### 2 layers of 100 and 250 perceptrons each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vungu\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8224222585924713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vungu\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\vungu\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\vungu\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62644853 0.48534424 0.7402863  0.75170532 0.72832765]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vungu\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,250))\n",
    "mlp.fit(X_train, y_train)\n",
    "print(mlp.score(X_train,y_train))\n",
    "print(cross_val_score(mlp,X_train,y_train,cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[434,  71],\n",
       "       [146, 164]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = mlp.predict(X_test)\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding more perceptrons but only 1 layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7614566284779051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vungu\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62235855 0.4805726  0.74982958 0.73874488 0.75221843]\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(1000,))\n",
    "mlp.fit(X_train, y_train)\n",
    "print(mlp.score(X_train,y_train))\n",
    "print(cross_val_score(mlp,X_train,y_train,cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[421,  84],\n",
       "       [131, 179]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = mlp.predict(X_test)\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 perceptron layers at 250 and 100 with alpha and learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7731860338243317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vungu\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.63735515 0.48261759 0.74437628 0.74010914 0.75494881]\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(250,100), alpha=1e-03, learning_rate='adaptive')\n",
    "mlp.fit(X_train,y_train)\n",
    "print(mlp.score(X_train,y_train))\n",
    "print(cross_val_score(mlp,X_train,y_train,cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[443,  62],\n",
       "       [151, 159]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = mlp.predict(X_test)\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 layers of 100 and 250 perceptrons each with alpha and learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vungu\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8240589198036007\n",
      "[0.64212679 0.4805726  0.76891616 0.74761255 0.73856655]\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(100,250), alpha=1e-03, learning_rate='adaptive')\n",
    "mlp.fit(X_train, y_train)\n",
    "print(mlp.score(X_train,y_train))\n",
    "print(cross_val_score(mlp,X_train,y_train,cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[386, 119],\n",
       "       [126, 184]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = mlp.predict(X_test)\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:\n",
      " {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.754228041462084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vungu\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\vungu\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\vungu\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75187457 0.47852761 0.74369461 0.7585266  0.75290102]\n",
      "[[452  53]\n",
      " [161 149]]\n",
      "Results on the test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.90      0.81       505\n",
      "         1.0       0.74      0.48      0.58       310\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       815\n",
      "   macro avg       0.74      0.69      0.70       815\n",
      "weighted avg       0.74      0.74      0.72       815\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vungu\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(max_iter=100)\n",
    "\n",
    "# define hyperparameters to try out\n",
    "parameters = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "\n",
    "# run gridsearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# n_jobs=-1 to max out all cpu cores\n",
    "bestmlp = GridSearchCV(mlp, parameters, n_jobs=-1, cv=5)\n",
    "bestmlp.fit(X_train, y_train)\n",
    "y_pred = bestmlp.predict(X_test)\n",
    "\n",
    "# Best paramete set\n",
    "print('Best parameters:\\n', bestmlp.best_params_)\n",
    "\n",
    "# All results\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(bestmlp.score(X_train,y_train))\n",
    "print(cross_val_score(bestmlp,X_train,y_train,cv=5))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('Results on the test set:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vungu\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:\n",
      " {'activation': 'tanh', 'alpha': 1e-05, 'hidden_layer_sizes': (40, 40, 40), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.7515002727768685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vungu\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\vungu\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\vungu\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\vungu\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75732788 0.72256305 0.74301295 0.74624829 0.75494881]\n",
      "[[437  68]\n",
      " [159 151]]\n",
      "Results on the test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.87      0.79       505\n",
      "         1.0       0.69      0.49      0.57       310\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       815\n",
      "   macro avg       0.71      0.68      0.68       815\n",
      "weighted avg       0.72      0.72      0.71       815\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vungu\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(max_iter=100)\n",
    "\n",
    "# define hyperparameters to try out\n",
    "parameters = {\n",
    "    'hidden_layer_sizes': [(40,40,40), (50,50,50)],\n",
    "    'activation': ['tanh'],\n",
    "    'solver': ['sgd'],\n",
    "    'alpha': [0.00001, 0.0001],\n",
    "    'learning_rate': ['constant'],\n",
    "}\n",
    "\n",
    "# run gridsearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# n_jobs=-1 to max out all cpu cores\n",
    "bestmlp = GridSearchCV(mlp, parameters, n_jobs=-1, cv=5)\n",
    "bestmlp.fit(X_train, y_train)\n",
    "y_pred = bestmlp.predict(X_test)\n",
    "\n",
    "# Best paramete set\n",
    "print('Best parameters:\\n', bestmlp.best_params_)\n",
    "\n",
    "# All results\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(bestmlp.score(X_train,y_train))\n",
    "print(cross_val_score(bestmlp,X_train,y_train,cv=5))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('Results on the test set:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vungu\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:\n",
      " {'activation': 'tanh', 'alpha': 1e-06, 'hidden_layer_sizes': (30, 30, 30), 'learning_rate': 'constant', 'solver': 'sgd'}\n",
      "0.7456355701036552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vungu\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\vungu\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\vungu\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\vungu\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76141786 0.72392638 0.732788   0.75102319 0.73583618]\n",
      "[[443  62]\n",
      " [150 160]]\n",
      "Results on the test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.88      0.81       505\n",
      "         1.0       0.72      0.52      0.60       310\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       815\n",
      "   macro avg       0.73      0.70      0.70       815\n",
      "weighted avg       0.74      0.74      0.73       815\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vungu\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(max_iter=100)\n",
    "\n",
    "# define hyperparameters to try out\n",
    "parameters = {\n",
    "    'hidden_layer_sizes': [(30,30,30),(40,40,40)],\n",
    "    'activation': ['tanh'],\n",
    "    'solver': ['sgd'],\n",
    "    'alpha': [0.000001, 0.00001],\n",
    "    'learning_rate': ['constant'],\n",
    "}\n",
    "\n",
    "# run gridsearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# n_jobs=-1 to max out all cpu cores\n",
    "bestmlp = GridSearchCV(mlp, parameters, n_jobs=-1, cv=5)\n",
    "bestmlp.fit(X_train, y_train)\n",
    "y_pred = bestmlp.predict(X_test)\n",
    "\n",
    "# Best paramete set\n",
    "print('Best parameters:\\n', bestmlp.best_params_)\n",
    "\n",
    "# All results\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(bestmlp.score(X_train,y_train))\n",
    "print(cross_val_score(bestmlp,X_train,y_train,cv=5))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('Results on the test set:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7573649754500819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vungu\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76278119 0.72528971 0.75051125 0.74283765 0.75494881]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[450,  55],\n",
       "       [159, 151]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(100,250), alpha=1e-06, learning_rate='constant', activation= 'tanh', solver= 'sgd')\n",
    "mlp.fit(X_train, y_train)\n",
    "print(mlp.score(X_train,y_train))\n",
    "print(cross_val_score(mlp,X_train,y_train,cv=5))\n",
    "\n",
    "y_pred = mlp.predict(X_test)\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vungu\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7340425531914894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vungu\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\vungu\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\vungu\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\vungu\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75528289 0.71915474 0.73960464 0.72169168 0.71604096]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vungu\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[455,  50],\n",
       "       [173, 137]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(100,250), alpha=1e-06, learning_rate='constant', activation= 'logistic', solver= 'sgd')\n",
    "mlp.fit(X_train, y_train)\n",
    "print(mlp.score(X_train,y_train))\n",
    "print(cross_val_score(mlp,X_train,y_train,cv=5))\n",
    "\n",
    "y_pred = mlp.predict(X_test)\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vungu\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7375886524822695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vungu\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\vungu\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\vungu\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\vungu\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75460123 0.71642808 0.74642127 0.72783083 0.72081911]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vungu\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[460,  45],\n",
       "       [172, 138]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(500,250), alpha=1e-06, learning_rate='constant', activation= 'logistic', solver= 'sgd')\n",
    "mlp.fit(X_train, y_train)\n",
    "print(mlp.score(X_train,y_train))\n",
    "print(cross_val_score(mlp,X_train,y_train,cv=5))\n",
    "\n",
    "y_pred = mlp.predict(X_test)\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vungu\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7527277686852155\n",
      "[0.7661895  0.73006135 0.76005453 0.74420191 0.74812287]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[443,  62],\n",
       "       [160, 150]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(1000,), alpha=1e-06, learning_rate='constant', activation= 'logistic', solver= 'sgd')\n",
    "mlp.fit(X_train, y_train)\n",
    "print(mlp.score(X_train,y_train))\n",
    "print(cross_val_score(mlp,X_train,y_train,cv=5))\n",
    "\n",
    "y_pred = mlp.predict(X_test)\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall:\n",
    "\n",
    "* Neural Network generally performs better than the Gradient Boost model.\n",
    "* Depends on the numbers of perceptrons and the hidden layers, neural network can take longer time to run, especially when combined with GridSearch then the run time takes significantly longer.\n",
    "* I had better accuracy score when I increase the size of the hidden layers to 1000. \n",
    "* Decreasing alpha level while also decreasing the number of perceptrons help addressing the overfitting issue, abeit at lower accuracy score on the training test.\n",
    "* I end up changing the activation method to logistic instead of the recommended tanh because this is a classification task; however, the accuracy scores also drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
